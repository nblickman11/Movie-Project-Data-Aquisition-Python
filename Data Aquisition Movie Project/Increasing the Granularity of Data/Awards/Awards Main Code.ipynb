{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DSCI 511: Data Acquisition and Pre-Processing - Final Project <br> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Increasing the Granularity of Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"4\">**3.1. Awards**<font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import urllib \n",
    "import requests\n",
    "import re\n",
    "from collections import defaultdict\n",
    "from collections import Counter\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "IMDB provides a detailed level of information about different types of awards, movie festivals or companies that these awards are sponsered by and whether a movie was only nominated for this award or won it as well. It is reasonable to summarize the frequency of pertinent data for each title, using counter object for the following data analysis objectives.\n",
    "\n",
    "- Below script extracts these information for up to 100 movies at once and eventually write the data that we get into a JSON file called \"awrds_clean\".\n",
    "\n",
    "- We will use `regex` and `Counter` to count the number of Awards from a particular Awards Company, and the Award Category."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "87572"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "    # 1. Line below opens the file.\n",
    "file = open(\"awards_clean.json\", \"w\")\n",
    "\n",
    "     # 2. The IMDB website lists 100 movies per page.  Hence, if we change our range below, to be \"range(1,10)\"...\n",
    "#...it would get information on 1,000 movies.\n",
    "# Next, we put the data into Beautiful Soup format, stored in \"soup\".  Page1 link is below to see the website:..\n",
    "#..link:  https://www.imdb.com/list/ls003495084/?sort=date_added,desc&st_dt=&mode=detail&page=1  \n",
    "i = 1\n",
    "for item in range(1,2):\n",
    "    url = 'https://www.imdb.com/list/ls003495084/?sort=date_added,desc&st_dt=&mode=detail&page=' + str(item)\n",
    "    html_text = urllib.request.urlopen(url).read()\n",
    "    soup = BeautifulSoup(html_text, 'html.parser')\n",
    "\n",
    "    # 3. Of the 100 movies on page 1, we grab every individual movie link. \n",
    "    movies={}\n",
    "    for x in soup.find_all('a'):\n",
    "        if x.get(\"href\") is not None:\n",
    "            if re.search('^/title/tt', x['href']) and x.text!=' \\n':\n",
    "                movies[x.text]={'link':'https://www.imdb.com/'+x['href']}     \n",
    "    \n",
    "    # ***Side note before we go to Step 4:  The link for each movie is exactly the same.  The only...\n",
    "#...difference in the links is a large number.  \n",
    "    \n",
    "    # 4.  Based on side note above, we decide to pull out these numbers in each link and put it into a..\n",
    "#...list called movie_numbers \n",
    "    movie_numbers = []\n",
    "    for key, dictionary in movies.items():\n",
    "        for values in dictionary.values():\n",
    "            movie_number = re.search(\"[0-9]+\", values)\n",
    "            movie_numbers.append(movie_number.group(0))\n",
    "    \n",
    "    \n",
    "    # 5. We can now iterate through movie_numbers (from step 4) to successfully reach in and grab the info...\n",
    "#...for the 100 individual movies.  In fact, we want to do more than this.  We want to click on our movie...\n",
    "#...link, but then we also want to click on the Awards link that is within that movie link.  Well, every...\n",
    "#...Awards link of each movie is also the same (besides for the movie number).  Therefore, we can iterate...\n",
    "#...through each movies inner awards link.\n",
    "# We will store the info from the awards page for each movie into a Beautiful Soup object called \"movie\".\n",
    "    Awards = {}\n",
    "    for number in movie_numbers:\n",
    "        def get_url(M):\n",
    "            return urllib.request.urlopen(\"https://www.imdb.com/title/tt\" + M + \"/awards?ref_=tt_ql_op_1\").read()\n",
    "        html_text = get_url(number)    \n",
    "        movie = BeautifulSoup(html_text, 'html.parser')\n",
    "        \n",
    "    # 6. The Beautiful Soup functions below creates two dictionaries.  One contains a list of the awards the..\n",
    "#.. movie was \"Nominated\" for, and the other holds the awards the movie \"Won.\"  Each dictionaries values\n",
    "#... lists the Company that gave the Award, the Award category, and names the individuals who won individual..\n",
    "#... awards. \n",
    "        tds = movie.find_all(\"td\")\n",
    "        d = defaultdict(list)\n",
    "        Win_Nom = ''\n",
    "        try:\n",
    "            for td in tds:\n",
    "                split_line = (td.text.split(\"\\n\"))\n",
    "                for line in split_line:\n",
    "                    if line == \"Nominee\":\n",
    "                        Win_Nom = 'Nominee'\n",
    "                    elif line == \"Winner\":\n",
    "                        Win_Nom = \"Winner\"\n",
    "                    elif Win_Nom == 'Nominee':\n",
    "                        piece = (line.split(\"  \"))\n",
    "                        if piece[0] != '': \n",
    "                            d[\"Nominee\"].append(line)    \n",
    "                        if len(piece) > 5:\n",
    "                            piece[6].strip()\n",
    "                            d[\"Nominee\"].append(piece[6])\n",
    "                    elif Win_Nom == \"Winner\":\n",
    "                        piece = line.split(\"  \")\n",
    "                        if piece[0] != '':\n",
    "                            d[\"Winner\"].append(line)\n",
    "                        if len(piece) > 1:\n",
    "                            piece[6].strip()\n",
    "                            d[\"Winner\"].append(piece[6])\n",
    "    \n",
    "    # 7.  The below code takes the two dictionaries from step 6, and creates a Counter structure which is...\n",
    "#... what we are going to dump into a JSON file.  However, it is possible that Step 6's dictionary structure..\n",
    "#... would be preferable for an analysis. \n",
    "            num_awards = Counter() \n",
    "            for keys, values in d.items():\n",
    "                for value in values:\n",
    "                    award_company = re.search(\"(.* Award)\", value)\n",
    "                    award_category = re.search(\"(Best .*)\", value)\n",
    "                    if award_company != None:\n",
    "                        num_awards[award_company.group(0)] = num_awards[award_company.group(0)] + 1\n",
    "                    if award_category != None:\n",
    "                        num_awards[award_category.group(0)] = num_awards[award_category.group(0)] + 1\n",
    "            Awards.update({str(i):num_awards})\n",
    "            i+=1\n",
    "                 \n",
    "    # 8.  Now, not every movie was able to be organized with the code above.  If so, the code below ran.\n",
    "# Everything is the same below, except for a couple of minor tweaks.  The only difference in the output...\n",
    "# is that there is extra white space in these dictionaries.  But, the Counter structure eliminates this...\n",
    "# extra white space !\n",
    "        except IndexError:\n",
    "            for td in tds:\n",
    "                split_line = (td.text.split(\"\\n\"))\n",
    "                for line in split_line:\n",
    "                    if line == \"Nominee\":\n",
    "                        Win_Nom = 'Nominee'\n",
    "                    elif line == \"Winner\":\n",
    "                        Win_Nom = \"Winner\"\n",
    "                    elif Win_Nom == 'Nominee':\n",
    "                        piece = (line.split(\"  \"))\n",
    "                        d[\"Nominee\"].append(line)    \n",
    "                    elif Win_Nom == \"Winner\":\n",
    "                        piece = line.split(\"  \")\n",
    "                        d[\"Winner\"].append(line)      \n",
    "    # 9.  The counter structure.\n",
    "            num_awards = Counter() \n",
    "            for keys, values in d.items():\n",
    "                for value in values:\n",
    "                    award_company = re.search(\"(.* Award)\", value)\n",
    "                    award_category = re.search(\"(Best .*)\", value)\n",
    "                    if award_company != None:\n",
    "                        num_awards[award_company.group(0)] = num_awards[award_company.group(0)] + 1\n",
    "                    if award_category != None:\n",
    "                        num_awards[award_category.group(0)] = num_awards[award_category.group(0)] + 1\n",
    "            Awards.update({str(i):num_awards})\n",
    "            i+=1\n",
    "            \n",
    "    # 10.  Finally, we can dump our Counter Structures for the 100 movies into a JSON format. \n",
    "counter_ds = json.dumps(Awards)\n",
    "file.write(counter_ds)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
